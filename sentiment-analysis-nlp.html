<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Don't Always Need LLMs: Sentiment Analysis</title>
    <link rel="icon" type="image/x-icon" href="ico.png" />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/themes/prism.min.css"
      rel="stylesheet"
    />

    <style>
      body {
        font-family: "Inter", sans-serif;
        font-weight: 300;
        line-height: 1.6;
        color: #333;
        background-color: #fafafa;
        max-width: 800px;
        margin: 0 auto;
        padding: 80px 20px 40px;
        font-size: 16px;
      }
      h1,
      h2,
      h3 {
        font-weight: 400;
        margin: 1.5em 0 0.5em 0;
        letter-spacing: -0.5px;
      }
      h1 {
        font-size: 32px;
      }
      h2 {
        font-size: 24px;
      }
      h3 {
        font-size: 20px;
      }
      p {
        margin: 0 0 20px 0;
      }
      a {
        color: #0066cc;
        text-decoration: none;
      }
      a:hover {
        text-decoration: underline;
      }
      pre[class*="language-"] {
        border-radius: 5px;
        margin: 1em 0;
      }
      code[class*="language-"] {
        font-size: 12px;
      }
      .math-block {
        overflow-x: auto;
        margin: 1em 0;
        padding: 1em;
        background-color: #f5f5f5;
        border-radius: 5px;
      }
      .signature {
        margin-top: 20px;
        color: #666;
      }
      @media (max-width: 600px) {
        body {
          padding-top: 60px;
          font-size: 14px;
        }
        h1 {
          font-size: 28px;
        }
        h2 {
          font-size: 22px;
        }
        h3 {
          font-size: 18px;
        }
      }
    </style>
  </head>
  <body>
    <article>
      <h1>Don't Always Need LLMs: Sentiment Analysis</h1>
      <h3>2024-09-04</h3>

      <p>
        It's clear that LLMs (large language models) are being integrated into
        nearly every corner of software these days. I understand—it's a powerful
        and versatile piece of technology with an immense number of applications
        and use cases. However, I'm concerned that engineers are becoming too
        complacent with using LLMs for everything, leading to a trend of
        applying "AI" to problems that could already be solved more efficiently
        with simpler methods.
      </p>

      <p>
        LLMs excel at NLP (natural language processing) because NLP largely
        involves identifying patterns in text. But when it comes to "simple" NLP
        tasks like sentiment analysis, these tasks can be done faster and more
        cheaply with some preexisting libraries. This is how I did it "back in
        the day" when building NLP pipelines using tools like
        <code>nltk</code> and <code>spaCy</code>. For most use cases—especially
        those involving individual, bite-sized pieces of text—the need for an
        LLM is irrelevant and often overkill or a case of excessive
        over-engineering.
      </p>

      <p>
        In this post, I will explore an LLM-based approach using LangChain to
        call GPT-4 for sentiment analysis and compare it with simpler, more
        traditional NLP methods using libraries like <code>VADER</code>,
        <code>nltk</code>, and <code>spaCy</code>. I aim to demonstrate that
        traditional NLP libraries provide a faster, more interpretable, and
        cost-effective solution for sentiment analysis in many cases, especially
        when you need more granular numerical sentiment scores rather than just
        broad positive or negative labels.
      </p>

      <h2>Sentiment Analysis Using GPT-4o via LangChain</h2>

      <p>
        To illustrate how LLMs can be used for sentiment analysis, let's use
        LangChain to call OpenAI's GPT-4o to perform the task. LangChain
        provides an easy interface to integrate with various LLMs, including
        OpenAI models.
      </p>

      <h3>Setup</h3>

      <p>First, you need to install LangChain and the OpenAI API client:</p>

      <pre><code class="language-bash">pip install langchain openai</code></pre>

      <p>You'll also need to set up your OpenAI API key:</p>

      <pre><code class="language-python">
import os
from langchain.llms import OpenAI

# Set up OpenAI API key
os.environ["OPENAI_API_KEY"] = "your-api-key"
      </code></pre>

      <h3>Example Using GPT-4o with LangChain</h3>

      <pre><code class="language-python">
from langchain.llms import OpenAI

# Initialize OpenAI model
llm = OpenAI(model_name="gpt-4o")

# Example text
text = "I absolutely love this product! It's amazing and works like a charm. Highly recommended."

# Create a prompt for sentiment analysis
prompt = f"Analyze the sentiment of the following text and provide the sentiment as 'Positive', 'Negative', or 'Neutral':\n\n{text}"

# Get sentiment analysis from GPT-4o
result = llm(prompt)
print(result)
      </code></pre>

      <p><strong>Output:</strong></p>
      <pre><code>The sentiment of the text is: Positive</code></pre>

      <h3>Limitations of Using LLMs for Sentiment Analysis</h3>

      <p>
        While GPT-4o provides a clear positive or negative label, it lacks the
        granularity and numeric detail that traditional NLP approaches offer.
        Furthermore, LLMs are not always great at mathematical calculations or
        consistently providing probability scores for different sentiments.
        Here's a breakdown of some key limitations:
      </p>

      <ul>
        <li>
          <strong>No Numeric Scores:</strong> GPT-4o provides a broad label
          ("Positive", "Negative", or "Neutral"), but you don't get detailed
          numerical scores that can help you understand the intensity of
          sentiment or compare different texts quantitatively
        </li>
        <li>
          <strong>Computational, Monetary Cost, and Vendor Lock-In:</strong>
          LLMs are computationally expensive and require more infrastructure to
          run compared to traditional methods. Additionally, every call to a
          hosted LLM has a cost associated with it, which can lead to higher
          expenses and potential vendor lock-in
        </li>

        <li>
          <strong>Not Always Accurate with Simple Math:</strong> LLMs can
          struggle with consistency in mathematical tasks, which can lead to
          inaccuracies when deriving confidence scores or when needing more
          detailed breakdowns of sentiment
        </li>
      </ul>

      <h2>Sentiment Analysis with VADER in <code>nltk</code></h2>

      <p>
        <strong>VADER (Valence Aware Dictionary and sEntiment Reasoner)</strong>
        is a simple rule-based sentiment analysis tool that is fast and works
        well on social media data. It comes packaged in
        <code>nltk</code> (Natural Language Toolkit), making it easy to
        integrate.
      </p>

      <h3>Example with VADER</h3>

      <p>To get started, install <code>nltk</code>:</p>

      <pre><code class="language-bash">pip install nltk</code></pre>

      <p>
        Next, import the necessary libraries and use VADER for sentiment
        analysis:
      </p>

      <pre><code class="language-python">
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk

nltk.download('vader_lexicon')

sia = SentimentIntensityAnalyzer()

text = "I absolutely love this product! It's amazing and works like a charm. Highly recommended."
scores = sia.polarity_scores(text)

print(scores)
      </code></pre>

      <p><strong>Output:</strong></p>
      <pre><code>{'neg': 0.0, 'neu': 0.306, 'pos': 0.694, 'compound': 0.9421}</code></pre>

      <p>VADER provides four scores:</p>
      <ul>
        <li>
          <strong>Negative (`neg`):</strong> Indicates the proportion of
          negative sentiment in the text
        </li>
        <li>
          <strong>Neutral (`neu`):</strong> Indicates the proportion of neutral
          sentiment
        </li>
        <li>
          <strong>Positive (`pos`):</strong> Indicates the proportion of
          positive sentiment
        </li>
        <li>
          <strong>Compound:</strong> A single score that aggregates the overall
          sentiment ranging from -1 (most negative) to +1 (most positive)
        </li>
      </ul>

      <p>
        This numeric output provides much more granularity than a simple
        "Positive" or "Negative" label. You can compare different texts,
        aggregate sentiment scores over time, or perform more detailed sentiment
        analysis.
      </p>

      <h2>
        Sentiment Analysis with <code>spaCy</code> and <code>TextBlob</code>
      </h2>

      <p>
        <strong>spaCy</strong> is a powerful NLP library that supports a variety
        of tasks, including sentiment analysis, although it doesn't provide a
        built-in sentiment analyzer like VADER. However, we can use the
        <code>TextBlob</code> library or integrate VADER with
        <code>spaCy</code>.
      </p>

      <p>Install <code>spaCy</code> and <code>TextBlob</code>:</p>

      <pre><code class="language-bash">pip install spacy textblob
python -m textblob.download_corpora</code></pre>

      <h3>Example with <code>TextBlob</code></h3>

      <pre><code class="language-python">
from textblob import TextBlob

text = "I absolutely love this product! It's amazing and works like a charm. Highly recommended."
blob = TextBlob(text)

print(blob.sentiment)
      </code></pre>

      <p><strong>Output:</strong></p>
      <pre><code>Sentiment(polarity=0.462, subjectivity=0.68)</code></pre>

      <p><code>TextBlob</code> provides:</p>
      <ul>
        <li>
          <strong>Polarity:</strong> A score between -1 (negative) and 1
          (positive)
        </li>
        <li>
          <strong>Subjectivity:</strong> A score between 0 (objective) and 1
          (subjective)
        </li>
      </ul>

      <p>
        These numerical outputs help when you want to understand not only
        whether the sentiment is positive or negative but also how strongly it
        leans one way or the other.
      </p>

      <h2>Combining Line-by-Line Analysis for Cumulative Sentiment Scores</h2>

      <p>
        Sometimes, you may want to analyze sentiment at a more granular level,
        such as sentence by sentence or line by line. This is particularly
        useful when the text is lengthy or contains multiple opinions. Here's
        how you can implement this using VADER:
      </p>

      <pre><code class="language-python">
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk

nltk.download('punkt_tab')

def analyze_paragraph_sentiment(paragraph):
    sia = SentimentIntensityAnalyzer()
    sentences = nltk.sent_tokenize(paragraph)

    cumulative_score = {'neg': 0, 'neu': 0, 'pos': 0, 'compound': 0}
    for sentence in sentences:
        score = sia.polarity_scores(sentence)
        print(f"Sentence: {sentence}")
        print(f"Scores: {score}")

        for key in cumulative_score:
            cumulative_score[key] += score[key]

    num_sentences = len(sentences)
    for key in cumulative_score:
        cumulative_score[key] /= num_sentences

    print("\nCumulative Sentiment Scores:", cumulative_score)

paragraph = """
I love the way this app is designed. It's intuitive and user-friendly. 
However, it tends to crash quite often, which is frustrating. The customer support is great, though.
"""

analyze_paragraph_sentiment(paragraph)
      </code></pre>

      <p><strong>Output:</strong></p>
      <pre><code>
Sentence: I love the way this app is designed.
Scores: {'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.6369}
Sentence: It's intuitive and user-friendly.
Scores: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}
Sentence: However, it tends to crash quite often, which is frustrating.
Scores: {'neg': 0.412, 'neu': 0.588, 'pos': 0.0, 'compound': -0.6808}
Sentence: The customer support is great, though.
Scores: {'neg': 0.0, 'neu': 0.37, 'pos': 0.63, 'compound': 0.7783}

Cumulative Sentiment Scores: {'neg': 0.103, 'neu': 0.6365, 'pos': 0.2605, 'compound': 0.1836}
      </code></pre>

      <h2>When To Use Lightweight Sentiment Analysis</h2>

      <ul>
        <li>
          <strong>Speed:</strong> For quick sentiment analysis tasks, especially
          on large datasets, tools like VADER are extremely fast compared to
          LLMs
        </li>
        <li>
          <strong>Simplicity:</strong> If your task is straightforward,
          lightweight tools are simpler to implement and deploy
        </li>
        <li>
          <strong>Cost Efficiency:</strong> For small to medium-sized projects,
          there's no need for the computational cost of running an LLM
        </li>
        <li>
          <strong>Numeric Scores:</strong> Traditional methods provide detailed
          sentiment scores that are essential for more in-depth analysis
        </li>
      </ul>

      <div class="signature">
        <p>the end</p>
      </div>
    </article>

    <a href="index.html" class="back-button">Back to Home</a>

    <!-- Prism JS for code highlighting -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/plugins/autoloader/prism-autoloader.min.js"></script>
  </body>
</html>
